{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38e97b19-ec2d-458d-933c-f51379c69aba",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-02-27T07:42:41.521607Z",
     "iopub.status.busy": "2025-02-27T07:42:41.521385Z",
     "iopub.status.idle": "2025-02-27T07:42:48.466087Z",
     "shell.execute_reply": "2025-02-27T07:42:48.465598Z",
     "shell.execute_reply.started": "2025-02-27T07:42:41.521589Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-27 15:42:45.364084: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FlashAttention2 is not installed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yhh/virtualenv-deep-learning/lib/python3.12/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "707994236d3b4fc38026c7b41c6cf23c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "from transformers import GenerationConfig\n",
    "import torch\n",
    "from mtkresearch.llm.prompt import MRPromptV3\n",
    "\n",
    "# model_params_size: either '3B' or '8B'\n",
    "model_params_size = '3B'\n",
    "model_id = f\"MediaTek-Research/Llama-Breeze2-{model_params_size}-Instruct-v0_1\"\n",
    "model = AutoModel.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    low_cpu_mem_usage=True,\n",
    "    trust_remote_code=True,\n",
    "    device_map='auto',\n",
    "    img_context_token_id=128212\n",
    ").eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True, use_fast=False)\n",
    "\n",
    "generation_config = GenerationConfig(\n",
    "  max_new_tokens=2048,\n",
    "  do_sample=True,\n",
    "  temperature=0.01,\n",
    "  top_p=0.01,\n",
    "  repetition_penalty=1.1,\n",
    "  eos_token_id=128009\n",
    ")\n",
    "\n",
    "prompt_engine = MRPromptV3()\n",
    "\n",
    "sys_prompt = 'You are a helpful AI assistant built by MediaTek Research. The user you are helping speaks Traditional Chinese and comes from Taiwan.'\n",
    "\n",
    "def _inference(tokenizer, model, generation_config, prompt, pixel_values=None):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    if pixel_values is None:\n",
    "        output_tensors = model.generate(**inputs, generation_config=generation_config)\n",
    "    else:\n",
    "        output_tensors = model.generate(**inputs, generation_config=generation_config, pixel_values=pixel_values.to(model.dtype))\n",
    "    output_str = tokenizer.decode(output_tensors[0])\n",
    "    return output_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26499636-fec7-4d24-8fc1-e4ccb6e3f4b5",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-02-27T07:43:05.355547Z",
     "iopub.status.busy": "2025-02-27T07:43:05.354842Z",
     "iopub.status.idle": "2025-02-27T07:43:30.098198Z",
     "shell.execute_reply": "2025-02-27T07:43:30.097722Z",
     "shell.execute_reply.started": "2025-02-27T07:43:05.355522Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': '深度學習是一種人工智慧技術，它模仿生物神經網路的結構和功能。這個方法使用多層的人工神經元來處理資料，類似於大腦中的神經細胞。透過訓練這些模型，深度學習可以從大量數據中學習並提高其預測或分類能力。\\n\\n在現代科技中，深度學習被廣泛應用於各種領域，如圖像識別、自然語言處理、機器翻譯以及自動駕駛等。它能夠有效地解決複雜問題，並且已經成為當今許多先進技術的核心部分。'}\n"
     ]
    }
   ],
   "source": [
    "conversations = [\n",
    "    {\"role\": \"system\", \"content\": sys_prompt},\n",
    "    {\"role\": \"user\", \"content\": \"請問什麼是深度學習？\"},\n",
    "]\n",
    "\n",
    "prompt = prompt_engine.get_prompt(conversations)\n",
    "output_str = _inference(tokenizer, model, generation_config, prompt)\n",
    "result = prompt_engine.parse_generated_str(output_str)\n",
    "print(result)\n",
    "# {'role': 'assistant', 'content': '深度學習是一種人工智慧技術，主要是透過模仿生物神經網路的結構和功能來實現。它利用大量數據進行訓練，以建立複雜的模型並使其能夠自主學習、預測或分類輸入資料。\\n\\n在深度學習中，通常使用多層的神經網路，每一層都包含許多相互連接的節點（稱為神經元）。這些神經元可以處理不同特徵的輸入資料，並將結果傳遞給下一層的神經元。隨著資料流向更高層次，這個過程逐漸捕捉到更抽象的概念或模式。\\n\\n深度學習已被廣泛應用於各種領域，如圖像識別、自然語言處理、語音識別以及遊戲等。它提供了比傳統機器學習方法更好的表現，因為它能夠從複雜且非線性的數據中提取出有用的資訊。'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5189091d-c0e5-4247-b9cb-725cc7e0046e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0400e0d8bdb1455283df8312c95ea3fe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "0b170b13d91d44e894a3128bba0e39db": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "1378e8c5faed45e987c79a1239a7a717": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "1f60719c722a483687b436082a75feeb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "707994236d3b4fc38026c7b41c6cf23c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_9c90dadfe409490cbd83d266218cc858",
        "IPY_MODEL_d92ba23bf1bf49dd8ebfbcb71300ef2c",
        "IPY_MODEL_cc99f3f83929410baf618f1088931ebd"
       ],
       "layout": "IPY_MODEL_0b170b13d91d44e894a3128bba0e39db"
      }
     },
     "79f8bd8481b34d0890c096a130f41899": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8cffaaa4be14442783236f6d4b9547f1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9c90dadfe409490cbd83d266218cc858": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_79f8bd8481b34d0890c096a130f41899",
       "style": "IPY_MODEL_8cffaaa4be14442783236f6d4b9547f1",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "cc99f3f83929410baf618f1088931ebd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_daf683ccd9e244b28452ba98a278b3c5",
       "style": "IPY_MODEL_0400e0d8bdb1455283df8312c95ea3fe",
       "value": " 2/2 [00:00&lt;00:00,  4.76it/s]"
      }
     },
     "d92ba23bf1bf49dd8ebfbcb71300ef2c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_1f60719c722a483687b436082a75feeb",
       "max": 2,
       "style": "IPY_MODEL_1378e8c5faed45e987c79a1239a7a717",
       "value": 2
      }
     },
     "daf683ccd9e244b28452ba98a278b3c5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
