{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38e97b19-ec2d-458d-933c-f51379c69aba",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-02-27T07:20:13.716460Z",
     "iopub.status.busy": "2025-02-27T07:20:13.716220Z",
     "iopub.status.idle": "2025-02-27T07:31:55.343190Z",
     "shell.execute_reply": "2025-02-27T07:31:55.342704Z",
     "shell.execute_reply.started": "2025-02-27T07:20:13.716442Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb48cb4c83d543568683597763e58859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/5.75k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f1175cf01354a8a84b90051611899af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_internvl_chat.py:   0%|          | 0.00/3.94k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/MediaTek-Research/Llama-Breeze2-3B-Instruct-v0_1:\n",
      "- configuration_internvl_chat.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "793e9208698f49a4b696bda0e89244ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_internvl_chat.py:   0%|          | 0.00/15.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/MediaTek-Research/Llama-Breeze2-3B-Instruct-v0_1:\n",
      "- modeling_internvl_chat.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22b653206ad54ba1a4c68ba2ce49a338",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/54.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caaa419f9dd34d51b0cfa9ba7e8236d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d989126a3df4f8fa364a2703fbcfa6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "425d64673b6744b88b7d951e3b591b1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f058a4a68be4fdfb3bf72c5f21c70c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00fc085687f14b738a72d5b456d52533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/69.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "203ffbb40c324f7fb6b4bf951732c700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/54.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8795fa4499d3457cad44861df41f9c7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43ffa159a52544639c6dee9c6210bcd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "from transformers import GenerationConfig\n",
    "import torch\n",
    "from mtkresearch.llm.prompt import MRPromptV3\n",
    "\n",
    "# model_params_size: either '3B' or '8B'\n",
    "model_params_size = '3B'\n",
    "model_id = f\"MediaTek-Research/Llama-Breeze2-{model_params_size}-Instruct-v0_1\"\n",
    "model = AutoModel.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    low_cpu_mem_usage=True,\n",
    "    trust_remote_code=True,\n",
    "    device_map='auto',\n",
    "    img_context_token_id=128212\n",
    ").eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True, use_fast=False)\n",
    "\n",
    "generation_config = GenerationConfig(\n",
    "  max_new_tokens=2048,\n",
    "  do_sample=True,\n",
    "  temperature=0.01,\n",
    "  top_p=0.01,\n",
    "  repetition_penalty=1.1,\n",
    "  eos_token_id=128009\n",
    ")\n",
    "\n",
    "prompt_engine = MRPromptV3()\n",
    "\n",
    "sys_prompt = 'You are a helpful AI assistant built by MediaTek Research. The user you are helping speaks Traditional Chinese and comes from Taiwan.'\n",
    "\n",
    "def _inference(tokenizer, model, generation_config, prompt, pixel_values=None):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    if pixel_values is None:\n",
    "        output_tensors = model.generate(**inputs, generation_config=generation_config)\n",
    "    else:\n",
    "        output_tensors = model.generate(**inputs, generation_config=generation_config, pixel_values=pixel_values.to(model.dtype))\n",
    "    output_str = tokenizer.decode(output_tensors[0])\n",
    "    return output_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26499636-fec7-4d24-8fc1-e4ccb6e3f4b5",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-02-27T07:32:53.933105Z",
     "iopub.status.busy": "2025-02-27T07:32:53.932930Z",
     "iopub.status.idle": "2025-02-27T07:33:19.645977Z",
     "shell.execute_reply": "2025-02-27T07:33:19.645536Z",
     "shell.execute_reply.started": "2025-02-27T07:32:53.933093Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': '深度學習是一種人工智慧技術，它模仿生物神經網路的結構和功能。這個方法使用多層的人工神經元來處理資料，類似於大腦中的神經細胞。透過訓練這些模型，深度學習可以從大量數據中學習並提高其預測或分類能力。\\n\\n在現代科技中，深度學習被廣泛應用於各種領域，如圖像識別、自然語言處理、機器翻譯以及自動駕駛等。它能夠有效地解決複雜問題，並且已經成為當今許多先進技術的核心部分。'}\n"
     ]
    }
   ],
   "source": [
    "conversations = [\n",
    "    {\"role\": \"system\", \"content\": sys_prompt},\n",
    "    {\"role\": \"user\", \"content\": \"請問什麼是深度學習？\"},\n",
    "]\n",
    "\n",
    "prompt = prompt_engine.get_prompt(conversations)\n",
    "output_str = _inference(tokenizer, model, generation_config, prompt)\n",
    "result = prompt_engine.parse_generated_str(output_str)\n",
    "print(result)\n",
    "# {'role': 'assistant', 'content': '深度學習是一種人工智慧技術，主要是透過模仿生物神經網路的結構和功能來實現。它利用大量數據進行訓練，以建立複雜的模型並使其能夠自主學習、預測或分類輸入資料。\\n\\n在深度學習中，通常使用多層的神經網路，每一層都包含許多相互連接的節點（稱為神經元）。這些神經元可以處理不同特徵的輸入資料，並將結果傳遞給下一層的神經元。隨著資料流向更高層次，這個過程逐漸捕捉到更抽象的概念或模式。\\n\\n深度學習已被廣泛應用於各種領域，如圖像識別、自然語言處理、語音識別以及遊戲等。它提供了比傳統機器學習方法更好的表現，因為它能夠從複雜且非線性的數據中提取出有用的資訊。'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5189091d-c0e5-4247-b9cb-725cc7e0046e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
