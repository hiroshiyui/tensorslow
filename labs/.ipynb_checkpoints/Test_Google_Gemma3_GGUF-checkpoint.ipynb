{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d15569a-b92b-49fe-8cb8-9b912796a1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "llm = Llama.from_pretrained(\n",
    "\trepo_id=\"ggml-org/gemma-3-4b-it-GGUF\",\n",
    "\tfilename=\"gemma-3-4b-it-Q4_K_M.gguf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d993ff28-04d0-4ad6-bb6d-b71fa9c9c1d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T10:18:13.449609Z",
     "iopub.status.busy": "2025-03-19T10:18:13.449457Z",
     "iopub.status.idle": "2025-03-19T10:18:30.387492Z",
     "shell.execute_reply": "2025-03-19T10:18:30.387180Z",
     "shell.execute_reply.started": "2025-03-19T10:18:13.449599Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8169.27 ms\n",
      "llama_perf_context_print: prompt eval time =    8169.17 ms /    25 tokens (  326.77 ms per token,     3.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    8679.37 ms /   149 runs   (   58.25 ms per token,    17.17 tokens per second)\n",
      "llama_perf_context_print:       total time =   16929.73 ms /   174 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 20s, sys: 383 ms, total: 2min 20s\n",
      "Wall time: 16.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-cb9c2d7b-835e-4e86-8e2a-d8fecada8a71',\n",
       " 'object': 'chat.completion',\n",
       " 'created': 1742379493,\n",
       " 'model': '/home/yhh/.cache/huggingface/hub/models--ggml-org--gemma-3-4b-it-GGUF/snapshots/43a5d3ad8b3e023836fea99a7f283f8ce1aa94b2/./gemma-3-4b-it-Q4_K_M.gguf',\n",
       " 'choices': [{'index': 0,\n",
       "   'message': {'role': 'assistant',\n",
       "    'content': \"您好！很高興能為您服務。請問有什麼我可以幫您的嗎？ (Nín hǎo! Hěn gāo xìng néng wèi nín fúwù. Qǐng wèn yǒu shénme wǒ kěyǐ bāng nín de ma?)\\n\\n(Hello! Pleased to be of service to you. Is there anything I can help you with?)\\n\\nLet me know what you'd like to talk about!  我會盡力用繁體中文與您交流。(Wǒ huì jìnlì yòng fánhtǐ zhōngwén yǔ nín jiāoliú.) (I will do my best to communicate with you in Traditional Chinese.)\"},\n",
       "   'logprobs': None,\n",
       "   'finish_reason': 'stop'}],\n",
       " 'usage': {'prompt_tokens': 25, 'completion_tokens': 149, 'total_tokens': 174}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "llm.create_chat_completion(\n",
    "      messages = [\n",
    "          {\"role\": \"system\", \"content\": \"You are an assistant who perfectly speaks Mandarin in Traditional script.\"},\n",
    "          {\n",
    "              \"role\": \"user\",\n",
    "              \"content\": \"您好！\"\n",
    "          }\n",
    "      ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4eec91-d8ad-4f96-9f02-5b847de25a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
